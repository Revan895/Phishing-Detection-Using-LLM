{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853f11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29396b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa2ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = pd.read_csv(\"Phishing_Email_Data/CEAS_08.csv\")\n",
    "df_02 = pd.read_csv(\"Phishing_Email_Data/Enron.csv\")\n",
    "df_03 = pd.read_csv(\"Phishing_Email_Data/Ling.csv\")\n",
    "df_04 = pd.read_csv(\"Phishing_Email_Data/Nazario.csv\")\n",
    "df_05 = pd.read_csv(\"Phishing_Email_Data/Nigerian_Fraud.csv\")\n",
    "df_06 = pd.read_csv(\"Phishing_Email_Data/phishing_email.csv\")\n",
    "df_07 = pd.read_csv(\"Phishing_Email_Data/SpamAssasin.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9045f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_01, df_02, df_03, df_04, df_05, df_06, df_07], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5944834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine subject and body into a single text field per email\n",
    "df[\"text\"] = df[\"subject\"].fillna(\"\") + \" \" + df[\"body\"].fillna(\"\")\n",
    "# Filter out emails that are empty or too short to be meaningful\n",
    "df = df[df[\"text\"].str.strip().str.len() > 20] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca274bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>receiver</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>urls</th>\n",
       "      <th>text_combined</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Young Esposito &lt;Young@iworld.de&gt;</td>\n",
       "      <td>user4@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 16:31:02 -0700</td>\n",
       "      <td>Never agree to be a loser</td>\n",
       "      <td>Buck up, your troubles caused by small dimensi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never agree to be a loser Buck up, your troubl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mok &lt;ipline's1983@icable.ph&gt;</td>\n",
       "      <td>user2.2@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 18:31:03 -0500</td>\n",
       "      <td>Befriend Jenna Jameson</td>\n",
       "      <td>\\nUpgrade your sex and pleasures with these te...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Befriend Jenna Jameson \\nUpgrade your sex and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daily Top 10 &lt;Karmandeep-opengevl@universalnet...</td>\n",
       "      <td>user2.9@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 20:28:00 -1200</td>\n",
       "      <td>CNN.com Daily Top 10</td>\n",
       "      <td>&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CNN.com Daily Top 10 &gt;+=+=+=+=+=+=+=+=+=+=+=+=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Parker &lt;ivqrnai@pobox.com&gt;</td>\n",
       "      <td>SpamAssassin Dev &lt;xrh@spamassassin.apache.org&gt;</td>\n",
       "      <td>Tue, 05 Aug 2008 17:31:20 -0600</td>\n",
       "      <td>Re: svn commit: r619753 - in /spamassassin/tru...</td>\n",
       "      <td>Would anyone object to removing .so from this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: svn commit: r619753 - in /spamassassin/tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gretchen Suggs &lt;externalsep1@loanofficertool.com&gt;</td>\n",
       "      <td>user2.2@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 19:31:21 -0400</td>\n",
       "      <td>SpecialPricesPharmMoreinfo</td>\n",
       "      <td>\\nWelcomeFastShippingCustomerSupport\\nhttp://7...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SpecialPricesPharmMoreinfo \\nWelcomeFastShippi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sender  \\\n",
       "0                   Young Esposito <Young@iworld.de>   \n",
       "1                       Mok <ipline's1983@icable.ph>   \n",
       "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
       "3                 Michael Parker <ivqrnai@pobox.com>   \n",
       "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
       "\n",
       "                                         receiver  \\\n",
       "0                     user4@gvc.ceas-challenge.cc   \n",
       "1                   user2.2@gvc.ceas-challenge.cc   \n",
       "2                   user2.9@gvc.ceas-challenge.cc   \n",
       "3  SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
       "4                   user2.2@gvc.ceas-challenge.cc   \n",
       "\n",
       "                              date  \\\n",
       "0  Tue, 05 Aug 2008 16:31:02 -0700   \n",
       "1  Tue, 05 Aug 2008 18:31:03 -0500   \n",
       "2  Tue, 05 Aug 2008 20:28:00 -1200   \n",
       "3  Tue, 05 Aug 2008 17:31:20 -0600   \n",
       "4  Tue, 05 Aug 2008 19:31:21 -0400   \n",
       "\n",
       "                                             subject  \\\n",
       "0                          Never agree to be a loser   \n",
       "1                             Befriend Jenna Jameson   \n",
       "2                               CNN.com Daily Top 10   \n",
       "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
       "4                         SpecialPricesPharmMoreinfo   \n",
       "\n",
       "                                                body  label  urls  \\\n",
       "0  Buck up, your troubles caused by small dimensi...      1   1.0   \n",
       "1  \\nUpgrade your sex and pleasures with these te...      1   1.0   \n",
       "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1   1.0   \n",
       "3  Would anyone object to removing .so from this ...      0   1.0   \n",
       "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...      1   1.0   \n",
       "\n",
       "  text_combined                                               text  \n",
       "0           NaN  Never agree to be a loser Buck up, your troubl...  \n",
       "1           NaN  Befriend Jenna Jameson \\nUpgrade your sex and ...  \n",
       "2           NaN  CNN.com Daily Top 10 >+=+=+=+=+=+=+=+=+=+=+=+=...  \n",
       "3           NaN  Re: svn commit: r619753 - in /spamassassin/tru...  \n",
       "4           NaN  SpecialPricesPharmMoreinfo \\nWelcomeFastShippi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee23d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    42882\n",
       "0    39592\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dde865ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Specify UTF-8 encoding (most common for text files)\n",
    "loader = TextLoader(\"security_guidelines.txt\", encoding=\"utf-8\")  \n",
    "security_docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "security_chunks = splitter.split_documents(security_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1088f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "# Create embeddings model — transforms text chunks into vectors\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Build FAISS vectorstore from your chunked security guideline documents\n",
    "vectorstore_guidelines = FAISS.from_documents(security_chunks, embedding)\n",
    "\n",
    "# Define a separate folder path for saving security guidelines index and metadata\n",
    "GUIDELINES_INDEX_PATH = \"security_faiss_index\"\n",
    "\n",
    "# Make sure the directory exists\n",
    "os.makedirs(GUIDELINES_INDEX_PATH, exist_ok=True)\n",
    "\n",
    "# Save the security guidelines vectorstore locally (index + metadata)\n",
    "vectorstore_guidelines.save_local(GUIDELINES_INDEX_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82585d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Create a list of Document objects from the DataFrame `df`\n",
    "documents = [\n",
    "    Document(\n",
    "        # Use the combined email text from the 'text' column as the main content\n",
    "        page_content=row['text'],  \n",
    "        \n",
    "        # Add metadata to each document indicating whether it's phishing or not,\n",
    "        # based on the 'label' column (1 means phishing, otherwise not phishing)\n",
    "        metadata={\"label\": \"Phishing\" if row['label'] == 1 else \"Not Phishing\"}\n",
    "    )\n",
    "    # Loop through each row of the DataFrame using `iterrows()`\n",
    "    for _, row in df.iterrows()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47489e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from document index: 71769\n",
      "Loaded existing FAISS index from disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches:   4%|▍         | 430/10705 [00:01<00:24, 423.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping document 71769 with 2955173 tokens — too large to embed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches:   6%|▋         | 673/10705 [00:01<00:19, 515.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping document 72302 with 380571 tokens — too large to embed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches: 100%|██████████| 10705/10705 [12:16<00:00, 14.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import tiktoken\n",
    "\n",
    "# Setup\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "tokenizer = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
    "\n",
    "MAX_TOKENS_PER_BATCH = 290_000  # keep below 300k limit for batch total tokens\n",
    "MAX_TOKENS_PER_DOC = 290_000    # max tokens allowed per single document to embed\n",
    "SLEEP_TIME = 1.5  # rate limit buffer\n",
    "INDEX_PATH = \"faiss_index\"\n",
    "PROGRESS_LOG = os.path.join(INDEX_PATH, \"embedding_progress.json\")\n",
    "\n",
    "# Make sure the index folder exists\n",
    "os.makedirs(INDEX_PATH, exist_ok=True)\n",
    "\n",
    "# Load your documents (list of Document objects)\n",
    "# documents = [ ... your docs from DataFrame as before ...]\n",
    "\n",
    "def num_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Load progress log or initialize it\n",
    "if os.path.exists(PROGRESS_LOG):\n",
    "    with open(PROGRESS_LOG, \"r\") as f:\n",
    "        progress_data = json.load(f)\n",
    "        start_idx = progress_data.get(\"last_index\", 0) + 1\n",
    "        print(f\"Resuming from document index: {start_idx}\")\n",
    "else:\n",
    "    start_idx = 0\n",
    "\n",
    "vectorstore = None\n",
    "current_batch = []\n",
    "current_tokens = 0\n",
    "\n",
    "# If index exists already, load it\n",
    "faiss_index_file = os.path.join(INDEX_PATH, \"index.faiss\")\n",
    "faiss_metadata_file = os.path.join(INDEX_PATH, \"index.pkl\")\n",
    "if os.path.exists(faiss_index_file) and os.path.exists(faiss_metadata_file):\n",
    "    vectorstore = FAISS.load_local(INDEX_PATH, embedding_model, allow_dangerous_deserialization=True)\n",
    "    print(\"Loaded existing FAISS index from disk.\")\n",
    "else:\n",
    "    print(\"No existing index found, starting fresh.\")\n",
    "\n",
    "for i in tqdm(range(start_idx, len(documents)), desc=\"Embedding batches\"):\n",
    "    doc = documents[i]\n",
    "    doc_tokens = num_tokens(doc.page_content)\n",
    "\n",
    "    # Skip docs that are too large to embed in one request\n",
    "    if doc_tokens > MAX_TOKENS_PER_DOC:\n",
    "        print(f\"Skipping document {i} with {doc_tokens} tokens — too large to embed.\")\n",
    "        with open(PROGRESS_LOG, \"w\") as f:\n",
    "            json.dump({\"last_index\": i}, f)\n",
    "        continue\n",
    "\n",
    "    # If adding this doc would exceed batch token limit, process current batch\n",
    "    if current_tokens + doc_tokens > MAX_TOKENS_PER_BATCH and current_batch:\n",
    "        texts = [d.page_content for d in current_batch]\n",
    "        metadatas = [d.metadata for d in current_batch]\n",
    "\n",
    "        batch_index = FAISS.from_texts(texts, embedding_model, metadatas=metadatas)\n",
    "        if vectorstore is None:\n",
    "            vectorstore = batch_index\n",
    "        else:\n",
    "            vectorstore.merge_from(batch_index)\n",
    "\n",
    "        # Save index and progress log after batch embedding\n",
    "        vectorstore.save_local(INDEX_PATH)\n",
    "        with open(PROGRESS_LOG, \"w\") as f:\n",
    "            json.dump({\"last_index\": i - 1}, f)\n",
    "\n",
    "        time.sleep(SLEEP_TIME)\n",
    "        current_batch = []\n",
    "        current_tokens = 0\n",
    "\n",
    "    # Add current doc to batch\n",
    "    current_batch.append(doc)\n",
    "    current_tokens += doc_tokens\n",
    "\n",
    "# Process any remaining documents after loop ends\n",
    "if current_batch:\n",
    "    texts = [d.page_content for d in current_batch]\n",
    "    metadatas = [d.metadata for d in current_batch]\n",
    "\n",
    "    batch_index = FAISS.from_texts(texts, embedding_model, metadatas=metadatas)\n",
    "    if vectorstore is None:\n",
    "        vectorstore = batch_index\n",
    "    else:\n",
    "        vectorstore.merge_from(batch_index)\n",
    "\n",
    "    vectorstore.save_local(INDEX_PATH)\n",
    "    with open(PROGRESS_LOG, \"w\") as f:\n",
    "        json.dump({\"last_index\": len(documents) - 1}, f)\n",
    "\n",
    "print(\"Embedding complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12939606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI \n",
    "\n",
    "# Load the GPT-3.5 Turbo model to use as our language model (LLM)\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\") #Controls randomness: 0 = fully deterministic outputs\n",
    "\n",
    "# Tells LangChain to retrieve based on semantic closeness and Fetches top 3 most relevant chunks per query\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) \n",
    "\n",
    "# For security guidelines\n",
    "retriever_guidelines = vectorstore_guidelines.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "\n",
    "# Build the QA pipeline: LLM + semantic retriever → answer generation\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "qa_chain_guidelines = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever_guidelines,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d26aa84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Phishing\n",
      "\n",
      "Reasoning: The email creates a sense of urgency by claiming the account has been flagged and will be suspended if the password is not reset immediately. The sender is simply identified as \"Admin\" without any specific information about the company or organization. The link provided could potentially lead to a phishing website designed to steal login credentials.\n",
      "\n",
      "Advice from similar emails:\n",
      " Based on the information provided, the email you received exhibits characteristics of a phishing attempt. Here are the recommended actions according to cybersecurity best practices:\n",
      "\n",
      "1. **Do not click the link:** Avoid clicking on any links in the email, especially if it is urging you to take immediate action.\n",
      "\n",
      "2. **Verify sender's email address:** Check the sender's email address carefully for any slight variations or spoofing that may indicate it is not from a legitimate source.\n",
      "\n",
      "3. **Hover over the link:** Hover over the link provided in the email to preview the URL without clicking on it. This can help you identify if the link is directing you to a malicious site.\n",
      "\n",
      "4. **Report the email:** If you suspect that the email is a phishing attempt, report it to your IT department or email provider so they can investigate further.\n",
      "\n",
      "5. **Do not trust urgent language:** Be cautious of emails that use urgent or threatening language to prompt you to take immediate action. Attackers often create urgency to manipulate users.\n",
      "\n",
      "6. **Consider enabling multi-factor authentication (MFA):** Adding an extra layer of security through MFA can help protect your accounts even if your password is compromised.\n",
      "\n",
      "Remember, it's always better to err on the side of caution when dealing with suspicious emails. If in doubt, verify the authenticity of the email through other means before taking any action.\n",
      "\n",
      "Advice from security guidelines:\n",
      " Based on cybersecurity best practices, if you receive an email like this, here are the recommended actions:\n",
      "\n",
      "1. **Verify sender information:** Check the sender's email address carefully to ensure it is legitimate. Look for any slight variations or spoofed addresses.\n",
      "\n",
      "2. **Do not trust urgent language:** Be cautious of urgent or threatening language in emails. Attackers often use urgency to prompt quick actions.\n",
      "\n",
      "3. **Hover before clicking:** Hover over the \"Reset Now\" link to preview the URL without clicking on it. Ensure that the link is directing you to a legitimate website.\n",
      "\n",
      "4. **Use email security tools:** Enable spam filters, anti-malware, and email authentication protocols like SPF, DKIM, and DMARC to enhance email security.\n",
      "\n",
      "5. **Enable multi-factor authentication (MFA):** Consider enabling MFA for an extra layer of security in case your account is compromised.\n",
      "\n",
      "6. **Do not click links:** Avoid clicking on links or opening attachments from unknown or suspicious senders. Instead, go directly to the official website of the service in question to reset your password.\n",
      "\n",
      "7. **Report suspicious emails:** If you suspect the email is a phishing attempt, report it to your IT department or email provider for further investigation.\n",
      "\n",
      "By following these best practices, you can help protect yourself from falling victim to phishing attacks.\n"
     ]
    }
   ],
   "source": [
    "# Email classification function\n",
    "def classify_email(email_text):\n",
    "    prompt = (\n",
    "        \"Evaluate whether the following email is a phishing attempt. \"\n",
    "        \"Reply with 'Phishing' or 'Not Phishing', and explain your reasoning based on cues like urgency, suspicious links, or sender identity.\\n\\n\"\n",
    "        f\"{email_text}\"\n",
    "    )\n",
    "    result = llm.predict(prompt)\n",
    "    return result.strip()\n",
    "\n",
    "# email\n",
    "email = \"\"\"\n",
    "Subject: Urgent Password Reset\n",
    "\n",
    "Dear User,\n",
    "\n",
    "Your account has been flagged. Please reset your password immediately using the link below or your account will be suspended.\n",
    "\n",
    "[Reset Now]\n",
    "\n",
    "Regards,\n",
    "Admin\n",
    "\"\"\"\n",
    "\n",
    "classification = classify_email(email)\n",
    "# Get advice from emails vectorstore QA chain\n",
    "advice_from_emails = qa_chain.invoke(\n",
    "    f\"What are the recommended actions according to cybersecurity best practices if I receive an email like this:\\n\\n{email}\"\n",
    ")\n",
    "\n",
    "# Get advice from security guidelines vectorstore QA chain\n",
    "advice_from_guidelines = qa_chain_guidelines.invoke(\n",
    "    f\"What are the recommended actions according to cybersecurity best practices if I receive an email like this:\\n\\n{email}\"\n",
    ")\n",
    "\n",
    "print(\"Classification:\", classification)\n",
    "print(\"\\nAdvice from similar emails:\\n\", advice_from_emails['result'])\n",
    "print(\"\\nAdvice from security guidelines:\\n\", advice_from_guidelines['result'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "419fad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Email chunk #1 ---\n",
      "Content:\n",
      "* * your account may suspend * * dear paypal member ,\n",
      "you have received this email as part of a verified paypal campaign meant to\n",
      "increase security for your credit card against online credit card fraud .\n",
      "verified paypal has detected that you have been using this email address for\n",
      "online purchases and in order to protect yourself against online credit card\n",
      "fraud we would like to introduce you to a new system that will protect you\n",
      "against frauds .\n",
      "you can associate your email address to your credit card and receive a\n",
      "password that you will use for any online purchase . also you will be notified\n",
      "by verified paypal when an online purchase is made .\n",
      "follow the below and go to verified paypal . you can join the verified paypal\n",
      "system or learn more about this .\n",
      "\n",
      "Metadata:\n",
      "{'label': 'Phishing'}\n",
      "\n",
      "\n",
      "--- Email chunk #2 ---\n",
      "Content:\n",
      "dear customer your details have been compromised dear customer :\n",
      "recently there have been a large number of cyber attacks pointing our database servers . in order to safeguard your account , we require you to sign on immediately .\n",
      "this personal check is requested of you as a precautionary measure and to ensure yourselves that everything is normal with your balance and personal information .\n",
      "this process is mandatory , and if you did not sign on within the nearest time your account may be subject to temporary suspension .\n",
      "please make sure you have your citibank ( r ) debit card number and your user id and password at hand .\n",
      "please use our secure counter server to indicate that you have signed on , please click the link bellow :\n",
      "http : / / 209 . 13 . 96 . 44 / citifi /\n",
      "! ! note that we have no particular indications that your details have been compromised in any way .\n",
      "thank you for your prompt attention to this matter and thank you for using citibank ( r )\n",
      "regards ,\n",
      "citibank ( r ) card department\n",
      "( c ) 2004 citibank . citibank , n . a . , citibank , f . s . b . ,\n",
      "citibank ( west ) , fsb . member fdic . citibank and arc\n",
      "design is a registered service mark of citicorp .\n",
      "Metadata:\n",
      "{'label': 'Phishing'}\n",
      "\n",
      "\n",
      "--- Email chunk #3 ---\n",
      "Content:\n",
      "dear customer your details have been compromised dear customer :\n",
      "recently there have been a large number of cyber attacks pointing our database servers . in order to safeguard your account , we require you to sign on immediately .\n",
      "this personal check is requested of you as a precautionary measure and to ensure yourselves that everything is normal with your balance and personal information .\n",
      "this process is mandatory , and if you did not sign on within the nearest time your account may be subject to temporary suspension .\n",
      "please make sure you have your citibank ( r ) debit card number and your user id and password at hand .\n",
      "please use our secure counter server to indicate that you have signed on , please click the link bellow :\n",
      "http : / / 221 . 4 . 199 . 8 / citifi /\n",
      "! ! note that we have no particular indications that your details have been compromised in any way .\n",
      "thank you for your prompt attention to this matter and thank you for using citibank ( r )\n",
      "regards ,\n",
      "citibank ( r ) card department\n",
      "( c ) 2004 citibank . citibank , n . a . , citibank , f . s . b . ,\n",
      "citibank ( west ) , fsb . member fdic . citibank and arc\n",
      "design is a registered service mark of citicorp .\n",
      "\n",
      "Metadata:\n",
      "{'label': 'Phishing'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(advice['source_documents'], 1):\n",
    "    print(f\"--- Email chunk #{i} ---\")\n",
    "    print(\"Content:\")\n",
    "    print(doc.page_content if doc.page_content else \"[No content]\")\n",
    "    print(\"Metadata:\")\n",
    "    print(doc.metadata)\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
