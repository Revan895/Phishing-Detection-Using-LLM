{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b5a8303",
   "metadata": {},
   "source": [
    "## 1. Implementation Overview\n",
    "\n",
    "This project integrates multiple phishing-related datasets into a unified database for embedding and retrieval using a RAG-based LLM architecture. The pipeline includes:\n",
    "\n",
    "- **Data Ingestion**: Seven datasets loaded via `pandas`, including CEAS, Enron, Ling, Nazario, Nigerian Fraud, phishing_email.csv, and SpamAssassin.\n",
    "- **Preprocessing**:\n",
    "  - Concatenation of `subject` and `body` into a single `text` field.\n",
    "  - Filtering of emails with fewer than 20 characters to reduce noise.\n",
    "- **Document Construction**: Each email is wrapped in a `Document` object with metadata indicating phishing status (`label`).\n",
    "- **Embedding**: Texts are embedded using OpenAI's API and stored in a FAISS vectorstore.\n",
    "- **Retrieval-Augmented Generation (RAG)**: Embedded documents are queried to support phishing classification and explanation via LLM.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f5759f",
   "metadata": {},
   "source": [
    "## 2. Technical Architecture\n",
    "\n",
    "- **Language Model**: OpenAI LLM (via API)\n",
    "- **Embedding Model**: `text-embedding-ada-002`\n",
    "- **Vectorstore**: FAISS with metadata filtering\n",
    "- **Document Format**: LangChain `Document` objects with `page_content` and `label` metadata\n",
    "- **Environment**: Python 3.12, LangChain, Pandas, FAISS, dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463cefc2",
   "metadata": {},
   "source": [
    "## 3. Challenges Encountered\n",
    "\n",
    "- **Restart Overhead**: Initial runs of the embedding pipeline were vulnerable to interruptions (e.g., API timeouts, memory limits), requiring full restarts that could take 30–45 minutes depending on batch size and dataset volume.\n",
    "- **Checkpointing Logic**: Embedding progress was not initially tracked\n",
    "- **Batch Management**: Large batches risked exceeding token limits or triggering rate caps; small batches increased total runtime and complexity.\n",
    "- **Embedding Limits**: OpenAI API rate limits and token constraints required batching and retry logic.\n",
    "\n",
    "To address these, the pipeline was refactored to include:\n",
    "- Persistent checkpointing via batch index tracking.\n",
    "- Modular embedding functions with resume capability.\n",
    "- FAISS index saving after each batch to prevent data loss.\n",
    "- Logging for each stage to support auditability and debugging.\n",
    "- Skipping the two largest emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12570aee",
   "metadata": {},
   "source": [
    "## 4. Key Learnings\n",
    "\n",
    "- **Modular Preprocessing** enables flexible dataset integration and rapid debugging.\n",
    "- **Metadata-Driven Retrieval** improves interpretability and classification accuracy.\n",
    "- **Audit-Friendly Design** (e.g., explicit label mapping, resume-safe batching) is essential for cybersecurity applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853f11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29396b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY_HERE\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa2ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = pd.read_csv(\"Phishing_Email_Data/CEAS_08.csv\")\n",
    "df_02 = pd.read_csv(\"Phishing_Email_Data/Enron.csv\")\n",
    "df_03 = pd.read_csv(\"Phishing_Email_Data/Ling.csv\")\n",
    "df_04 = pd.read_csv(\"Phishing_Email_Data/Nazario.csv\")\n",
    "df_05 = pd.read_csv(\"Phishing_Email_Data/Nigerian_Fraud.csv\")\n",
    "df_06 = pd.read_csv(\"Phishing_Email_Data/phishing_email.csv\")\n",
    "df_07 = pd.read_csv(\"Phishing_Email_Data/SpamAssasin.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9045f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_01, df_02, df_03, df_04, df_05, df_06, df_07], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5944834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine subject and body into a single text field per email\n",
    "df[\"text\"] = df[\"subject\"].fillna(\"\") + \" \" + df[\"body\"].fillna(\"\")\n",
    "# Filter out emails that are empty or too short to be meaningful\n",
    "df = df[df[\"text\"].str.strip().str.len() > 20] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca274bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>receiver</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>urls</th>\n",
       "      <th>text_combined</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Young Esposito &lt;Young@iworld.de&gt;</td>\n",
       "      <td>user4@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 16:31:02 -0700</td>\n",
       "      <td>Never agree to be a loser</td>\n",
       "      <td>Buck up, your troubles caused by small dimensi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never agree to be a loser Buck up, your troubl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mok &lt;ipline's1983@icable.ph&gt;</td>\n",
       "      <td>user2.2@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 18:31:03 -0500</td>\n",
       "      <td>Befriend Jenna Jameson</td>\n",
       "      <td>\\nUpgrade your sex and pleasures with these te...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Befriend Jenna Jameson \\nUpgrade your sex and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daily Top 10 &lt;Karmandeep-opengevl@universalnet...</td>\n",
       "      <td>user2.9@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 20:28:00 -1200</td>\n",
       "      <td>CNN.com Daily Top 10</td>\n",
       "      <td>&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CNN.com Daily Top 10 &gt;+=+=+=+=+=+=+=+=+=+=+=+=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Parker &lt;ivqrnai@pobox.com&gt;</td>\n",
       "      <td>SpamAssassin Dev &lt;xrh@spamassassin.apache.org&gt;</td>\n",
       "      <td>Tue, 05 Aug 2008 17:31:20 -0600</td>\n",
       "      <td>Re: svn commit: r619753 - in /spamassassin/tru...</td>\n",
       "      <td>Would anyone object to removing .so from this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Re: svn commit: r619753 - in /spamassassin/tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gretchen Suggs &lt;externalsep1@loanofficertool.com&gt;</td>\n",
       "      <td>user2.2@gvc.ceas-challenge.cc</td>\n",
       "      <td>Tue, 05 Aug 2008 19:31:21 -0400</td>\n",
       "      <td>SpecialPricesPharmMoreinfo</td>\n",
       "      <td>\\nWelcomeFastShippingCustomerSupport\\nhttp://7...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SpecialPricesPharmMoreinfo \\nWelcomeFastShippi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sender  \\\n",
       "0                   Young Esposito <Young@iworld.de>   \n",
       "1                       Mok <ipline's1983@icable.ph>   \n",
       "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
       "3                 Michael Parker <ivqrnai@pobox.com>   \n",
       "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
       "\n",
       "                                         receiver  \\\n",
       "0                     user4@gvc.ceas-challenge.cc   \n",
       "1                   user2.2@gvc.ceas-challenge.cc   \n",
       "2                   user2.9@gvc.ceas-challenge.cc   \n",
       "3  SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
       "4                   user2.2@gvc.ceas-challenge.cc   \n",
       "\n",
       "                              date  \\\n",
       "0  Tue, 05 Aug 2008 16:31:02 -0700   \n",
       "1  Tue, 05 Aug 2008 18:31:03 -0500   \n",
       "2  Tue, 05 Aug 2008 20:28:00 -1200   \n",
       "3  Tue, 05 Aug 2008 17:31:20 -0600   \n",
       "4  Tue, 05 Aug 2008 19:31:21 -0400   \n",
       "\n",
       "                                             subject  \\\n",
       "0                          Never agree to be a loser   \n",
       "1                             Befriend Jenna Jameson   \n",
       "2                               CNN.com Daily Top 10   \n",
       "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
       "4                         SpecialPricesPharmMoreinfo   \n",
       "\n",
       "                                                body  label  urls  \\\n",
       "0  Buck up, your troubles caused by small dimensi...      1   1.0   \n",
       "1  \\nUpgrade your sex and pleasures with these te...      1   1.0   \n",
       "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1   1.0   \n",
       "3  Would anyone object to removing .so from this ...      0   1.0   \n",
       "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...      1   1.0   \n",
       "\n",
       "  text_combined                                               text  \n",
       "0           NaN  Never agree to be a loser Buck up, your troubl...  \n",
       "1           NaN  Befriend Jenna Jameson \\nUpgrade your sex and ...  \n",
       "2           NaN  CNN.com Daily Top 10 >+=+=+=+=+=+=+=+=+=+=+=+=...  \n",
       "3           NaN  Re: svn commit: r619753 - in /spamassassin/tru...  \n",
       "4           NaN  SpecialPricesPharmMoreinfo \\nWelcomeFastShippi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee23d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    42882\n",
       "0    39592\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dde865ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Specify UTF-8 encoding (most common for text files)\n",
    "loader = TextLoader(\"security_guidelines.txt\", encoding=\"utf-8\")  \n",
    "security_docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "security_chunks = splitter.split_documents(security_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1088f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "# Create embeddings model — transforms text chunks into vectors\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Build FAISS vectorstore from your chunked security guideline documents\n",
    "vectorstore_guidelines = FAISS.from_documents(security_chunks, embedding)\n",
    "\n",
    "# Define a separate folder path for saving security guidelines index and metadata\n",
    "GUIDELINES_INDEX_PATH = \"security_faiss_index\"\n",
    "\n",
    "# Make sure the directory exists\n",
    "os.makedirs(GUIDELINES_INDEX_PATH, exist_ok=True)\n",
    "\n",
    "# Save the security guidelines vectorstore locally (index + metadata)\n",
    "vectorstore_guidelines.save_local(GUIDELINES_INDEX_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82585d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Create a list of Document objects from the DataFrame `df`\n",
    "documents = [\n",
    "    Document(\n",
    "        # Use the combined email text from the 'text' column as the main content\n",
    "        page_content=row['text'],  \n",
    "        \n",
    "        # Add metadata to each document indicating whether it's phishing or not,\n",
    "        # based on the 'label' column (1 means phishing, otherwise not phishing)\n",
    "        metadata={\"label\": \"Phishing\" if row['label'] == 1 else \"Not Phishing\"}\n",
    "    )\n",
    "    # Loop through each row of the DataFrame using `iterrows()`\n",
    "    for _, row in df.iterrows()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47489e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from document index: 71769\n",
      "Loaded existing FAISS index from disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches:   4%|▍         | 430/10705 [00:01<00:24, 423.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping document 71769 with 2955173 tokens — too large to embed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches:   6%|▋         | 673/10705 [00:01<00:19, 515.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping document 72302 with 380571 tokens — too large to embed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches: 100%|██████████| 10705/10705 [12:16<00:00, 14.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import tiktoken\n",
    "\n",
    "# Setup\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "tokenizer = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
    "\n",
    "MAX_TOKENS_PER_BATCH = 290_000  # keep below 300k limit for batch total tokens\n",
    "MAX_TOKENS_PER_DOC = 290_000    # max tokens allowed per single document to embed\n",
    "SLEEP_TIME = 1.5  # rate limit buffer\n",
    "INDEX_PATH = \"faiss_index\"\n",
    "PROGRESS_LOG = os.path.join(INDEX_PATH, \"embedding_progress.json\")\n",
    "\n",
    "# Make sure the index folder exists\n",
    "os.makedirs(INDEX_PATH, exist_ok=True)\n",
    "\n",
    "# Load your documents (list of Document objects)\n",
    "# documents = [ ... your docs from DataFrame as before ...]\n",
    "\n",
    "def num_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Load progress log or initialize it\n",
    "if os.path.exists(PROGRESS_LOG):\n",
    "    with open(PROGRESS_LOG, \"r\") as f:\n",
    "        progress_data = json.load(f)\n",
    "        start_idx = progress_data.get(\"last_index\", 0) + 1\n",
    "        print(f\"Resuming from document index: {start_idx}\")\n",
    "else:\n",
    "    start_idx = 0\n",
    "\n",
    "vectorstore = None\n",
    "current_batch = []\n",
    "current_tokens = 0\n",
    "\n",
    "# If index exists already, load it\n",
    "faiss_index_file = os.path.join(INDEX_PATH, \"index.faiss\")\n",
    "faiss_metadata_file = os.path.join(INDEX_PATH, \"index.pkl\")\n",
    "if os.path.exists(faiss_index_file) and os.path.exists(faiss_metadata_file):\n",
    "    vectorstore = FAISS.load_local(INDEX_PATH, embedding_model, allow_dangerous_deserialization=True)\n",
    "    print(\"Loaded existing FAISS index from disk.\")\n",
    "else:\n",
    "    print(\"No existing index found, starting fresh.\")\n",
    "\n",
    "for i in tqdm(range(start_idx, len(documents)), desc=\"Embedding batches\"):\n",
    "    doc = documents[i]\n",
    "    doc_tokens = num_tokens(doc.page_content)\n",
    "\n",
    "    # Skip docs that are too large to embed in one request\n",
    "    if doc_tokens > MAX_TOKENS_PER_DOC:\n",
    "        print(f\"Skipping document {i} with {doc_tokens} tokens — too large to embed.\")\n",
    "        with open(PROGRESS_LOG, \"w\") as f:\n",
    "            json.dump({\"last_index\": i}, f)\n",
    "        continue\n",
    "\n",
    "    # If adding this doc would exceed batch token limit, process current batch\n",
    "    if current_tokens + doc_tokens > MAX_TOKENS_PER_BATCH and current_batch:\n",
    "        texts = [d.page_content for d in current_batch]\n",
    "        metadatas = [d.metadata for d in current_batch]\n",
    "\n",
    "        batch_index = FAISS.from_texts(texts, embedding_model, metadatas=metadatas)\n",
    "        if vectorstore is None:\n",
    "            vectorstore = batch_index\n",
    "        else:\n",
    "            vectorstore.merge_from(batch_index)\n",
    "\n",
    "        # Save index and progress log after batch embedding\n",
    "        vectorstore.save_local(INDEX_PATH)\n",
    "        with open(PROGRESS_LOG, \"w\") as f:\n",
    "            json.dump({\"last_index\": i - 1}, f)\n",
    "\n",
    "        time.sleep(SLEEP_TIME)\n",
    "        current_batch = []\n",
    "        current_tokens = 0\n",
    "\n",
    "    # Add current doc to batch\n",
    "    current_batch.append(doc)\n",
    "    current_tokens += doc_tokens\n",
    "\n",
    "# Process any remaining documents after loop ends\n",
    "if current_batch:\n",
    "    texts = [d.page_content for d in current_batch]\n",
    "    metadatas = [d.metadata for d in current_batch]\n",
    "\n",
    "    batch_index = FAISS.from_texts(texts, embedding_model, metadatas=metadatas)\n",
    "    if vectorstore is None:\n",
    "        vectorstore = batch_index\n",
    "    else:\n",
    "        vectorstore.merge_from(batch_index)\n",
    "\n",
    "    vectorstore.save_local(INDEX_PATH)\n",
    "    with open(PROGRESS_LOG, \"w\") as f:\n",
    "        json.dump({\"last_index\": len(documents) - 1}, f)\n",
    "\n",
    "print(\"Embedding complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affaee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom RetrievalQA subclass that changes how retrieved documents are combined\n",
    "class CustomRetrievalQA(RetrievalQA):\n",
    "    def combine_documents(self, docs, question, **kwargs):\n",
    "        # Instead of just concatenating document text,\n",
    "        # we first call `format_docs_with_labels(docs)`,\n",
    "        # which injects the \"Label: ...\" metadata into the text for the LLM to see.\n",
    "        similar_emails_text = format_docs_with_labels(docs)\n",
    "        \n",
    "        # Then we pass that labeled text into a custom prompt template,\n",
    "        # so the LLM receives both the content AND the classification label\n",
    "        # for each retrieved example email.\n",
    "        return custom_prompt.format(similar_emails=similar_emails_text, query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12939606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T\\AppData\\Local\\Temp\\ipykernel_4484\\83177682.py:27: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class LabelInjectingRetriever(BaseRetriever, BaseModel):\n",
      "C:\\Users\\T\\AppData\\Local\\Temp\\ipykernel_4484\\83177682.py:27: DeprecationWarning: Retrievers must implement abstract `_aget_relevant_documents` method instead of `aget_relevant_documents`\n",
      "  class LabelInjectingRetriever(BaseRetriever, BaseModel):\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.schema.retriever import BaseRetriever\n",
    "\n",
    "# Load GPT-3.5 Turbo with deterministic output (temperature=0)\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Create retrievers that pull the 3 most semantically similar chunks per query\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "retriever_guidelines = vectorstore_guidelines.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "\n",
    "# This helper takes each retrieved Document and\n",
    "# prepends its stored phishing label from metadata before the actual content.\n",
    "# This is the **critical step** that ensures the LLM sees both the label and the email text.\n",
    "def format_docs_with_labels(docs):\n",
    "    parts = []\n",
    "    for doc in docs:\n",
    "        # Grab label from metadata (added when docs were stored in the vector DB)\n",
    "        label = doc.metadata.get(\"label\", \"Unknown\")\n",
    "        # Create a readable chunk: \"[Label: X]\\n<email text>\"\n",
    "        parts.append(f\"[Label: {label}]\\n{doc.page_content}\")\n",
    "    # Separate each doc with a visual divider\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)\n",
    "\n",
    "\n",
    "# Wrapper retriever that doesn't change the retrieval logic\n",
    "# but makes it easy to inject our label-formatting step later.\n",
    "class LabelInjectingRetriever(BaseRetriever, BaseModel):\n",
    "    base_retriever: BaseRetriever = Field(...)\n",
    "\n",
    "    def get_relevant_documents(self, query):\n",
    "        # Just fetch the raw docs (labels already live in metadata)\n",
    "        return self.base_retriever.get_relevant_documents(query)\n",
    "\n",
    "    async def aget_relevant_documents(self, query):\n",
    "        return self.get_relevant_documents(query)\n",
    "\n",
    "    \n",
    "# Wrap the original retrievers with our label-aware wrapper\n",
    "wrapped_retriever = LabelInjectingRetriever(base_retriever=retriever)\n",
    "wrapped_retriever_guidelines = LabelInjectingRetriever(base_retriever=retriever_guidelines)\n",
    "\n",
    "# Standard RetrievalQA chain, but since we're using the wrapped retriever,\n",
    "# any docs retrieved still have their label metadata available for formatting.\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=wrapped_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "qa_chain_guidelines = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever_guidelines,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26aa84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Based on the examples provided, the new email should be classified as 'Phishing'. The common characteristics among the labeled phishing emails include urgent language, threats of account suspension, requests to click on suspicious links, and claims of unusual activities on the account. \n",
      "\n",
      "The new email exhibits similar characteristics such as urgency in the subject line, a warning about the account being flagged, and a request to reset the password immediately using a link provided in the email. These are all red flags commonly associated with phishing attempts. \n",
      "\n",
      "Therefore, based on the patterns observed in the labeled phishing emails, it is likely that the new email is also a phishing attempt.\n",
      "\n",
      "Advice from similar emails:\n",
      " The email you received seems to be a phishing attempt. Here are some recommended actions according to cybersecurity best practices:\n",
      "\n",
      "1. **Do not click on any links**: Avoid clicking on any links or downloading any attachments in the email. These links could lead to malicious websites or download malware onto your device.\n",
      "\n",
      "2. **Verify the sender**: Check the sender's email address. If it looks suspicious or unfamiliar, do not trust the email.\n",
      "\n",
      "3. **Contact the company directly**: If you are unsure about the legitimacy of the email, contact the company or organization directly using a verified phone number or email address to confirm if the email is genuine.\n",
      "\n",
      "4. **Check for spelling and grammar errors**: Phishing emails often contain spelling and grammar mistakes. If you notice any errors, it's likely a phishing attempt.\n",
      "\n",
      "5. **Report the email**: If you suspect that the email is a phishing attempt, report it to your email provider as spam or phishing.\n",
      "\n",
      "Remember, legitimate companies will never ask you to provide sensitive information like passwords via email.\n",
      "\n",
      "Advice from security guidelines:\n",
      " Based on cybersecurity best practices, if you receive an email like this, here are the recommended actions:\n",
      "\n",
      "1. **Verify sender information:** Check the sender's email address carefully to ensure it is legitimate. If it seems suspicious or unfamiliar, do not click on any links or provide any information.\n",
      "\n",
      "2. **Do not trust urgent language:** Be cautious of urgent or threatening language in emails. Attackers often use urgency to manipulate users into taking hasty actions.\n",
      "\n",
      "3. **Hover before clicking:** Hover over the \"Reset Now\" link to preview the URL without clicking on it. Make sure the URL is legitimate and not a malicious site.\n",
      "\n",
      "4. **Use email security tools:** Enable spam filters, anti-malware, and email authentication protocols like SPF, DKIM, and DMARC to help identify and block phishing attempts.\n",
      "\n",
      "5. **Enable multi-factor authentication (MFA):** If you receive such emails, it's a good reminder to ensure that MFA is enabled on your accounts for an extra layer of security.\n",
      "\n",
      "6. **Do not click links or open attachments:** Avoid clicking on any links or opening attachments from unknown or suspicious senders, especially if the email is requesting urgent action.\n",
      "\n",
      "7. **Report suspicious emails:** If you suspect that the email is a phishing attempt, report it to your IT department or email provider so they can investigate and take appropriate action.\n",
      "\n",
      "Remember, it's always better to err on the side of caution when dealing with suspicious emails.\n"
     ]
    }
   ],
   "source": [
    "# Example email to classify\n",
    "email = \"\"\"\n",
    "Subject: Urgent Password Reset\n",
    "\n",
    "Dear User,\n",
    "\n",
    "Your account has been flagged. Please reset your password immediately using the link below or your account will be suspended.\n",
    "\n",
    "[Reset Now]\n",
    "\n",
    "Regards,\n",
    "Admin\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def classify_email(email_text):\n",
    "    # Step 1: Retrieve similar example emails from the vectorstore\n",
    "    similar_docs = wrapped_retriever.get_relevant_documents(email_text)\n",
    "    \n",
    "    # Step 2: Inject each doc's label into the visible text for the LLM\n",
    "    labeled_similar_emails = format_docs_with_labels(similar_docs)\n",
    "    \n",
    "    # Step 3: Construct a prompt that shows the LLM:\n",
    "    #   - The labeled examples (from Step 2)\n",
    "    #   - The new email that needs classifying\n",
    "    prompt_text = (\n",
    "        \"You are a cybersecurity expert. Here are some similar emails with their phishing labels:\\n\\n\"\n",
    "        f\"{labeled_similar_emails}\\n\\n\"\n",
    "        \"Please carefully analyze these examples and their labels.\\n\"\n",
    "        \"Using that information, classify the following new email as 'Phishing' or 'Not Phishing'.\\n\"\n",
    "        \"In your explanation, explicitly reference how the examples influenced your decision.\\n\\n\"\n",
    "        f\"New email:\\n{email_text}\"\n",
    "    )\n",
    "    \n",
    "    # Step 4: Ask the LLM to make a classification and explain\n",
    "    response = llm.predict(prompt_text)\n",
    "    \n",
    "    # Return classification + the docs that were shown to the LLM\n",
    "    return response.strip(), similar_docs\n",
    "\n",
    "classification, similar_docs = classify_email(email)\n",
    "\n",
    "# Now we can also get recommendations from the two QA chains\n",
    "advice_from_emails = qa_chain.invoke(\n",
    "    f\"What are the recommended actions according to cybersecurity best practices if I receive an email like this, , if it's not a phishing email, don't give any advice:\\n\\n{email}\"\n",
    ")\n",
    "\n",
    "advice_from_guidelines = qa_chain_guidelines.invoke(\n",
    "    f\"What are the recommended actions according to cybersecurity best practices if I receive an email like this, , if it's not a phishing email, don't give any advice:\\n\\n{email}\"\n",
    ")\n",
    "\n",
    "print(\"Classification:\", classification)\n",
    "print(\"\\nAdvice from similar emails:\\n\", advice_from_emails['result'])\n",
    "print(\"\\nAdvice from security guidelines:\\n\", advice_from_guidelines['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "419fad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Emails Retrieved and Their Labels:\n",
      "\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "Rv-Staff-Email Access Dear Staff\n",
      "\n",
      "\n",
      "Your e-mailbox password will soon expire. to validate your e-mail or you will be temporary block Please confirm the link below to Update your e-mail\n",
      "\n",
      "\n",
      "Click the link https://au-mai.webnode.com/\n",
      "\n",
      "\n",
      "Thank you,\n",
      "\n",
      "IT Support\n",
      "\n",
      "CONFIDENTIALITY NOTE:  The information contained in this transmission may contain privileged and confidential information, including patient information protected by federal and state privacy laws. It is intended only for the use of the person(s) named above. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution, or duplication of this communication is strictly prohibited. Please contact the sender by reply email and destroy all copies of the original message. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "Help Desk Password Update Staff  Validate E-mail\n",
      "\n",
      "\n",
      "Your email will be blocked within the next 24hours, to reset your email Please Click the link below\n",
      "\n",
      "https://www.powr.io/plugins/form-builder/view?id=4031776&mode=page\n",
      "\n",
      "\n",
      "IT-Service Help Desk\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "[Label: Phishing]\n",
      "Your Account Logon Reminder Just to let you know that we noticed unusual activites on your online account during our regular update today. It is either your details have been changed or incomplete. As a result of the technical issues detected your online account has been temporarily suspended. You are therefore required to verify your details to regain access to online service. Please click the link below in order to regain instant access. Click here to regain access Internet support team.\t     \t  \t               \t   Disclaimer This email was sent from a notification-only address that does not accept email replies. Please do not reply directly to this email.       Just to let you know that we noticed unusual activites on your online account during our regular update today. It is either your details have been changed or incomplete.As a result of the technical issues detected your online account has been temporarily suspended. You are therefore required to verify your details to regain access to online service. Please click the link below in order to regain instant access.Click here to regain accessInternet support team.         DisclaimerThis email was sent from a notification-only address that does not accept email replies. Please do not reply directly to this email.\n"
     ]
    }
   ],
   "source": [
    "print(\"Similar Emails Retrieved and Their Labels:\\n\")\n",
    "print(format_docs_with_labels(similar_docs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
